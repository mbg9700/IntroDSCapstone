---
title: "Classification of Homeless Deaths with Machine Learning"
author: "MBG"
date: "December 29, 2018"
output: 
  github_document:
      toc: TRUE
---

```{r echo=FALSE, message = FALSE }
library(caTools)
library(magrittr)
library(tidyverse)
library(stringr)
library(knitr)
library(naniar)
library(dplyr)
library(epiDisplay)
library(ROCR)
library(tm)
library(SnowballC)
library(wordcloud)
library(e1071)
library(gmodels)
library(caret)
library(klaR)
knitr::opts_chunk$set(message = FALSE, error=FALSE, fig.width = 9, fig.align = "center")
```

## I. LOGISTIC REGRESSION

### READ AND SUBSET DATA

I created two versions of the dataset containing my dependent and independent variables.  The first one includes "unknown" values as valid levels in factor variables and the second one recodes them to NAs.

```{r}
homeless <- read.csv("HomelessFinal.csv")
str(homeless)
h1 <- subset(homeless, select= c("sex", "raceethnic5", "manner", "dplacecode", "educ", "age5cat", "LCOD", "status", "injury", "substance"))
summary(h1)

#limit dataset to random sample of 2,200 with home and all homeless deaths

withhome <- subset(h1, status=="With home")
homeless <- subset(h1, status=="Homeless")
whsample <- sample_n(withhome, 2200)
h1 <- rbind(whsample, homeless)

h1$homeless[h1$status=="Homeless"] <- 1
h1$homeless[h1$status=="With home"] <- 0

h1$homeless <- factor(h1$homeless)

h2 <- h1

levels(h2$sex)[levels(h2$sex)=="U"] <- NA
levels(h2$raceethnic5)[6] <- NA
levels(h2$manner)[4] <- NA
levels(h2$educ)[4] <- NA
summary(h2)

```



### SPLIT DATA INTO TRAINING AND TESTING SUBSETS

```{r}
split = sample.split(h2$homeless, SplitRatio = 0.65)
HTrain = subset(h2, split==TRUE)
HTest = subset(h2, split==FALSE)
```


### CREATE MODEL

In this attempt I use the dataset that does not retain "unknown" values as valid levels in factor variables.

I specified the reference categories in each factor variable within the model. 
  
```{r roc curve}


HTrain$sex <- relevel(HTrain$sex, ref = "F")
HTrain$raceethnic5 <-relevel(HTrain$raceethnic5, ref = "White NH")
HTrain$manner <- relevel(HTrain$manner, ref = "Natural")
HTrain$dplacecode <- relevel(HTrain$dplacecode, ref = "Home")
HTrain$edu <- relevel(HTrain$educ, ref =  "<=8th grade")
HTrain$age5cat <- relevel(HTrain$age5cat, ref = "65+ yrs")
HTrain$injury <- relevel(HTrain$injury, ref = "No injury")
HTrain$substance <- relevel(HTrain$substance, ref = "No Substance abuse")
HTrain$LCOD <- relevel(HTrain$LCOD, ref = "Other")

## model 1 with all independent variables included
LR1 <- glm(homeless ~ sex + raceethnic5 + manner + dplacecode + educ + age5cat + injury + substance + LCOD, data = HTrain, family = "binomial")

summary(LR1)

LR1tab <- coef(summary(LR1))
#LR1tab[,2] <- exp(coef(LR1))
LR1tab
#exp(coef(LR1))

## ROC curve for model 1
#lroc(LR1)

```


####  Evaluating logistic regression model 1 performance

  1. Residuals - 50% of the errors in predictions (between 1st and 3rd quartiles) are within an odds ratio of 0.95 to 0.98 away from the true value.
  2. A number of independent variables are statistically significantly positively associated with the dependent variable (homelessness at death). Many of these make sense given the relationship between homeless status at death and these independent variables as seen in the exploratory data anlaysis phase. These include: 
    - being male, 
    - being American Indian/Native American non-Hispanic, 
    - being Hispanic, 
    - dying from an accidental cause, an undetermined cause, or homicide (manner of death), 
    - dying in a location designated by the death certifier as "other" or "other person's home",
    - age at death from 18 to 64 years old,
    - dying of alcohol or drug induced causes,
    - dying of influenza or heart disease.
  3. The ROC curve indicates an AUC of almost 97% indicating that the model has high sensitivity and specificity. 
    
    
### APPLY MODEL 1 TO THE TEST DATA SET TO EVALUATE MODEL

I set the threshold probability level at 0.5 i.e. if the model predicts that there's a greater than 0.5 probability that the observation is homeless then it is classified as a homeless death.  Tabulating the predicted values against the actual recorded ones gives the confusion matrix.

```{r}
predict1 <- predict(LR1, type = "response", newdata = HTest)
table(HTest$homeless, predict1 > 0.5)

```

Accuracy of model = accurate predictions/total # observations

```{r}

## model accuracy
(561+333)/(561+333+45+41)


## baseline accuracy - if baseline predicted all outcomes as 0
(561+45)/(561+333+45+41)

```

The model accuracy is 91% - the model predicts the homeless deaths correctly 333 times out of 374 actual homeless deaths. Baseline accuracy is 62% so the model prediction accuracy is better than baseline.


### Out of sample AUC
```{r}
ROCRpred1 = prediction(predict1, HTest$homeless)
as.numeric(performance(ROCRpred1, "auc")@y.values)
ROCRperf1 = performance(ROCRpred1, measure = "tpr",x.measure = "fpr")
plot(ROCRperf1, col = rainbow(10))

```


It looks like the model has a high out of sample accuracy of 96% as well.

OK - this STILL seems too good to be true even after creating a 1/3, 2/3 split between homeless and with home data.  What am I missing?

II. (A) NAIVE BAYES CLASSIFIER - using package e1071

```{r}
# get data and restrict to only literal fields
#the literal field in this dataset is called "CODliteral" and contains 
#Cause of death lines a-d, other significant conditions line, and injury
#occurrance literal field.

literal <- read.csv("HomelessFinal.csv", stringsAsFactors = FALSE)
literal <- subset(literal, select = c(status, CODliteral))
str(literal)

# set "status" to factor

literal$status <- factor(literal$status)
str(literal$status)
table(literal$status)

# to remove the problem of unbalanced data I will restrict the "with home" class to about 7,500 randomly selected records

h <- subset(literal, status=="Homeless")
wh <- subset(literal, status=="With home")
summary(h)
summary(wh)
wh_sample <- sample_n(wh, 7500)

literal2 <- rbind(wh_sample, h)
literal2 <- literal2[sample(nrow(literal2)), ] #randomize order of rows so rows aren't ordered by class
summary(literal2)

```


### Create corpus and prepare data

```{r}

h_corpus <- VCorpus(VectorSource(literal2$CODliteral))
print(h_corpus)
lapply(h_corpus[1:3], as.character)

X <- h_corpus

#standardize all content

X <- tm_map(X, content_transformer(tolower))

X <- tm_map(X, removeNumbers)

X <- tm_map(X, removePunctuation)

CODstop <- c("disease", "combination", "an", "the", "a", "of", "effects", "combined", "due", "to", "by", "acute", "chronic", "and", "failure", "intoxication", "type", "stage", "end", "natural", "on", "unspecified", "arrest", "atrial", "fibrilation", "coronary", "congestive", "history", "diastolic", "advanced", "probable", "with", "multiple", "small", "non", "event" ,"advanced" ,  "asymptomatic" ,  "autoimmune" ,  "benign"  ,  "clinical" ,  "communicable" ,"congenital" ,  "degenerative" ,  "febrile" ,  "first-degree" ,  "foca" ,  "fungal" ,  "generalized" ,  "inactive" ,  "infectious" , "inflammatory" ,  "invasive" ,  "local",  "morbid" ,"multiple" ,  "noninvasive" ,  "nonspecific" ,   "parasitic" , " pathological" ,  "perforated" ,  "primary" ,  "psychiatric" ,  "rheumatic" ,  "second-degree" ,  "severe" ,  "sporadic" ,  "suspected" ,  "systemic" ,  "terminal" ,  "third-degree" , " unresponsive ",  "untreated" ,  "viral" ,  "virulent" ,  "wasting", "exposure", "abuse", "unknown", "if", "cause", "death", "use", "in", "with")

X <- tm_map(X, removeWords, stopwords())
X <- tm_map(X, removeWords, CODstop)

lapply(X[1:3], as.character)


```


### Stemming words

```{r}
#Stemming

X <- tm_map(X, wordStem, language = "eng")
X<- tm_map(X, PlainTextDocument)
lapply(X[1:3], as.character)
# remove extra whitespace
X <- tm_map(X, stripWhitespace)
#X<- tm_map(X, PlainTextDocument)
#X <- tm_map(X, trimws)

as.character(X[[2]])

```


### Create document term matrix

```{r}

X_DTM <- DocumentTermMatrix(X)
X_DTM


```

### Creating training and test datasets

```{r}

TrainData <- X_DTM[1:6444, ]
TestData <- X_DTM[6445:8593, ]

# create vector of labels for later use

HTrainLabels <- literal2[1:6444, ]$status
HTestLabels <- literal2[6445:8593, ]$status

#confirm equal proportions of homeless and with home in each dataset

prop.table(table(HTrainLabels))
prop.table(table(HTestLabels))

```

### Create word cloud

```{r}

CODstop <- c("disease", "combination", "an", "the", "a", "of", "effects", "combined", "due", "to", "by", "acute", "chronic", "and", "failure", "intoxication", "type", "stage", "end", "natural", "on", "unspecified", "arrest", "atrial", "fibrilation", "coronary", "congestive", "history", "diastolic", "advanced", "probable", "with", "multiple", "small", "non", "event" ,"advanced" ,  "asymptomatic" ,  "autoimmune" ,  "benign"  ,  "clinical" ,  "communicable" ,"congenital" ,  "degenerative" ,  "febrile" ,  "first-degree" ,  "foca" ,  "fungal" ,  "generalized" ,  "inactive" ,  "infectious" , "inflammatory" ,  "invasive" ,  "local",  "morbid" ,"multiple" ,  "noninvasive" ,  "nonspecific" ,   "parasitic" , " pathological" ,  "perforated" ,  "primary" ,  "psychiatric" ,  "rheumatic" ,  "second-degree" ,  "severe" ,  "sporadic" ,  "suspected" ,  "systemic" ,  "terminal" ,  "third-degree" , " unresponsive ",  "untreated" ,  "viral" ,  "virulent" ,  "wasting", "exposure", "abuse", "unknown", "if", "cause", "death", "use", "in", "with", "other", "found")

hcloud <-data.frame(h$CODliteral)
names(hcloud) <- "lit"
hcloud.corpus <- Corpus((VectorSource(hcloud$lit)))
hcorp <- tm_map(hcloud.corpus, removePunctuation)
hcorp <- tm_map(hcorp, removeNumbers)
hcorp <- tm_map(hcorp, content_transformer(tolower))
hcorp <- tm_map(hcorp, removeWords, CODstop)
hcorp <- tm_map(hcorp, stripWhitespace)
hcorp <- tm_map(hcorp, stemDocument)
  
htdm <- TermDocumentMatrix(hcorp)
hm <- as.matrix(htdm)
hv <- sort(rowSums(hm), decreasing = TRUE)
hd <- data.frame(word = names(hv), freq = hv, stringsAsFactors = FALSE)
head(hd, 10)


whcloud <-wh_sample$CODliteral
whcloud <- data.frame(whcloud)
colnames(whcloud)<- "lit"
whcloud.corpus <- Corpus((VectorSource(whcloud$lit)))
whcorp <- tm_map(whcloud.corpus, removePunctuation)
whcorp <- tm_map(whcorp, removeNumbers)
whcorp <- tm_map(whcorp, content_transformer(tolower))
whcorp <- tm_map(whcorp, removeWords, CODstop)
whcorp <- tm_map(whcorp, stripWhitespace)
whcorp <- tm_map(whcorp, stemDocument)
  
whtdm <- TermDocumentMatrix(whcorp)
whm <- as.matrix(whtdm)
whv <- sort(rowSums(whm), decreasing = TRUE)
whd <- data.frame(word = names(whv), freq = whv, stringsAsFactors = FALSE)
head(whd, 10)

wordcloud::wordcloud(words = hd$word, freq = hd$freq, min.freq =25, max.words = 50, scale = c(3, 0.5))
wordcloud::wordcloud(words = whd$word, freq = whd$freq, min.freq =25, max.words = 50, scale = c(3, 0.5))

```


### Transform sparse matrix into data structure to train model

Eliminate words appearing in fewer than 5 records.

```{r}

freqWords <- findFreqTerms(TrainData, 5) #keeps words that appear at least 5 times
str(freqWords)

#filter DTM to keep only terms appearing 5 times or more

TrainData_filtered <- TrainData[ ,freqWords]
TestData_filtered <- TestData[ ,freqWords]

#Create function to convert counts to Yes/No variable indicating presence/absence of word

convertCounts <- function(x) {
  x <- ifelse(x>0, "Yes", "No")
}

Train_final <- apply(TrainData_filtered, MARGIN = 2, convertCounts) #Margin = 2: apply filter to columns
Test_final <- apply(TestData_filtered, MARGIN = 2, convertCounts)

```

### Train Naive Bayes model with 10-fold crossvalidation

```{r}
#train model

H_classifier <- naiveBayes(Train_final, HTrainLabels, laplace = 1, trainControl(method = 'cv', number = 10))

#use model to predict with test data

H_predict <- predict(H_classifier, Test_final)

#Evaluate accuracy of model by crosstabulating with raw data

CrossTable(H_predict, HTestLabels, 
           prop.chisq = FALSE,
           prop.t = FALSE,
           prop.r = FALSE,
           dnn = c("predicted", "actual"))

confusionMatrix(H_predict, HTestLabels, positive = "Homeless")

```



NEXT STEPS:

1. what other ways are there to "balance" the data between homeless and with home that doesn't require random selection of a subset of with home records? Is there a weighting technique that would allow me to keep all records?

2. How do I tweak the model to give me better accuracy?


## II. (B) NAIVE BAYES CLASSIFIER - using packages caret and klaR

```{r}
# start with data set h2 which contains the predictors most strongly associated with the outcome "status"
# as seen in the exploratory data analysis section

str(h2)

split = sample.split(h2$homeless, SplitRatio = 0.70)# create a 70:30 train: test data split
train.nb2 = subset(h2, split==TRUE)
test.nb2 = subset(h2, split==FALSE)

prop.table(table(train.nb2$status))
prop.table(table(test.nb2$status))


xtrain = train.nb2[,-11]
ytrain = train.nb2$status

xtest = test.nb2[, -11]
ytest = test.nb2$status

model.nb2 = train(xtrain, ytrain, 'nb', trControl=trainControl(method = 'cv', number = 10))
model.nb2

predict.nb2 = predict(model.nb2$finalModel, xtest)
predict.nb2
confusionMatrix(predict.nb2$class,ytest, positive = "Homeless")


```


## III. RANDOM FORESTS

```{r}
##
library(randomForest)
# use h2 data set created for logistic regression

summary(h2)
str(h2)

# Split into training and testing sets 70:30 (random)

split2 = sample.split(h2$homeless, SplitRatio = 0.70)
train.rf = subset(h2, split2==TRUE)
test.rf = subset(h2, split2==FALSE)

str(train.rf)
prop.table(table(train.rf$status))

str(test.rf)
prop.table(table(test.rf$status))


# create a random forest model with default parameters

rfmodel1 <-randomForest(status ~ ., data = train.rf, importance=TRUE, na.action = na.roughfix)

rfmodel1

```


```{r}
## Predicting on training set

rfpredict1 <- predict(rfmodel1, train.rf, type = "class")

# check classification accuracy - using training data

table(rfpredict1, train.rf$status)

# predicting on test/validation data

rfpredict2 <- predict(rfmodel1, test.rf, type = "class")

# check classification accuracy - using test/validation data

table(rfpredict2, test.rf$status)


```

```{r}
# Random forests using caret package
str(train.rf)
control <- trainControl(method = "repeatedcv", number = 10, repeats = 3, search = "grid")
tunegrid <- expand.grid(.mtry = c(1:6))
model.rfgrid <- train(homeless ~ ., data = train.rf, method = "rf", tuneGrid = tunegrid, trControl = control, na.action = na.roughfix)
print(model.rfgrid)
plot(model.rfgrid)
```


